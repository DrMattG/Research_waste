---
output:
  html_document: 
    fig_caption: yes
  output: 
  pdf_document:
    fig_caption: yes
  word_document: 
    fig_caption: yes
bibliography: bibliography.bib
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(ggrepel)
```


**A worked example of cumulative meta-analysis to identify research waste**

We extracted the data and R code from @darras2018comparing to recreate their analysis. Building on their random effects meta-analysis we ran a cumulative meta-analysis using the “cumul” function in the “metafor” package (@metafor) in R. The cumulative meta-analysis was ordered by publication year and plotted using the “forest” function.  To assess the point at which there is sufficient evidence and no further investigations are required we plotted the z-curve in relation to the cumulative sample size. The thresholds for significance was a z value of 1.96 or -1.96. When the z curve crosses this threshold then the level of evidence is considered sufficient. This approach (known as “trial sequential analysis”) is well developed in medicine (wetterslev2008trial). Plots were produced using ggplot2 in R (@ggplot2).

The effect size of studies investigating the difference between autonomous acoustic recorders and human observers in terms of bird species richness estimates was consistently close to 0 in each study (Figure 1). Trial sequential analysis shows that an evidence threshold was reached in 2015. This suggests that studies undertaken post 2015 were a waste of research resources.

```{r Make use of the code from Darras et al, message=FALSE, warning=FALSE, include=FALSE}
#Load libraries
library(readr)
library(data.table)
library(ggplot2)
library(scales)
library(cowplot)
library(metafor)
library(nlme)
library(MuMIn)
library(effects)
library(tidyverse)

#Code from the original paper (Darras et al. 2018)
#Prepare data and Run metaanalysis
#standard error function
se <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))

meta0=fread("meta-analysis - data.csv")
#give ID to all studies
meta0[,study_ID:=1:nrow(meta0)]
#remove Acevedo due to unequal sampling
meta0=meta0[first_author!="Acevedo"]
#convert to numeric
meta0=meta0[,total_time_min:=as.numeric(total_time_min)]

# Table 1 -----------------------------------------------------------------

#format column headers
meta.studies=meta0[,.(Publication=paste(first_author,year),`Sampling time (min)`=total_time_min,Microphone=microphone,`Signal to noise ratio (minimum, dB)`=signal_to_noise,`Height (cm)`=height_cm,`Number of Microphones`=number_microphones)]

# community differences ---------------------------------------------------

#compute total richness with both methods combined
meta0[,c("gamma_total_unlimited","gamma_total_identical")
      :=.(gamma_point_unlimited+unique_sound_unlimited,gamma_point_identical+unique_sound_identical)]

meta0[simultaneous_methods==1,.(common_species_unlimited=mean((gamma_point_unlimited-unique_point_unlimited)/gamma_total_unlimited,na.rm=T)
                                ,unique_point_unlimited=mean(unique_point_unlimited/gamma_total_unlimited,na.rm=T)
                                ,unique_sound_unlimited=mean(unique_sound_unlimited/gamma_total_unlimited,na.rm=T)
                                ,common_species_identical=mean((gamma_point_identical-unique_point_identical)/gamma_total_identical,na.rm=T)
                                ,unique_point_identical=mean(unique_point_identical/gamma_total_identical,na.rm=T)
                                ,unique_sound_identical=mean(unique_sound_identical/gamma_total_identical,na.rm=T))]

# calculate ROM ----------------------------------------------------------

#calculate log transformed ratio of means for alpha and gamma richness
#alpha richness identical
alpha.identical=data.table(summary(escalc(measure="ROM"
                                          ,m1i=alpha_sound_identical,m2i=alpha_point_identical
                                          ,sd1i=alpha_sound_sd_identical,sd2i=alpha_point_sd_identical
                                          ,n1i=alpha_sound_n_identical,n2i=alpha_point_n_identical
                                          ,data=meta0[!is.na(alpha_point_n_identical)])))

#alpha richness unlimited
alpha.unlimited=data.table(summary(escalc(measure="ROM"
                                          ,m1i=alpha_sound_unlimited,m2i=alpha_point_unlimited
                                          ,sd1i=alpha_sound_sd_unlimited,sd2i=alpha_point_sd_unlimited
                                          ,n1i=alpha_sound_n_unlimited,n2i=alpha_point_n_unlimited
                                          ,data=meta0[!is.na(alpha_point_n_unlimited)])))
#gamma richness identical
gamma.identical=data.table(summary(escalc(measure="ROM"
                                          ,m1i=gamma_sound_identical,m2i=gamma_point_identical
                                          ,sd1i=rep(0,nrow(meta0[!is.na(gamma_total_identical)])),sd2i=rep(0,nrow(meta0[!is.na(gamma_total_identical)]))
                                          ,n1i=total_time_min,n2i=total_time_min
                                          ,data=meta0[!is.na(gamma_total_identical)])))

#gamma richness unlimited
gamma.unlimited=data.table(summary(escalc(measure="ROM"
                                          ,m1i=gamma_sound_unlimited,m2i=gamma_point_unlimited
                                          ,sd1i=rep(0,nrow(meta0[!is.na(gamma_total_unlimited)])),sd2i=rep(0,nrow(meta0[!is.na(gamma_total_unlimited)]))
                                          ,n1i=total_time_min,n2i=total_time_min
                                          ,data=meta0[!is.na(gamma_total_unlimited)])))

#merge all ROM data together
meta1=merge(meta0,merge(alpha.identical[,.(study_ID,alpha_ROM_identical=yi,alpha_variance_ROM_identical=vi,alpha_ci.lb_identical=ci.lb,alpha_ci.ub_identical=ci.ub)]
                        ,merge(alpha.unlimited[,.(study_ID,alpha_ROM_unlimited=yi,alpha_variance_ROM_unlimited=vi,alpha_ci.lb_unlimited=ci.lb,alpha_ci.ub_unlimited=ci.ub)]
                               ,merge(gamma.unlimited[,.(study_ID,gamma_ROM_unlimited=yi,gamma_variance_ROM_unlimited=vi)]
                                      ,gamma.identical[,.(study_ID,gamma_ROM_identical=yi,gamma_variance_ROM_identical=vi)]
                                      ,all=T,by="study_ID"),all=T,by="study_ID"),all=T,by="study_ID"),all=T,by="study_ID")


# identical range (alpha) --------------------------------------------------------------

#create publication=level column for random effect
meta1[,publication:=paste(first_author,year)]

#models for identical ranges
RMA_alpha_identical=rma.mv(yi=alpha_ROM_identical,V=alpha_variance_ROM_identical
                           ,data=meta1,random=list(~1|publication))

```


```{r Add Trial, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= "Figure 1. Cumulative forest plot of the meta-analysis of Darras et al. (2018) on the difference between human observers and acoustic recorders in terms of species richness.\\label{forest}"}

res <- rma(RMA_alpha_identical$yi, RMA_alpha_identical$vi, data=meta1, slab=paste(meta1$first_author, meta1$year, sep=", "))
cres<-cumul(res, order=order(meta1$year))
forest(cres)
#png("Figures/Figure1.png")
#dev.off()

```


```{r Add seq, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= "Figure 2. Trial sequential analysis. The red dashed lines indicate the significance threshold (between -1.96 and 1.96). When the z-curve crosses the red line then there is sufficient evidence and no new trials are required. \\label{seq}"}

cres$total_time<-c(1360,150,40,480,7500,560,1440,2210,2210,290,570,300,600,2000,720,40,480,80,1730,100,590,4610,640,440,3140,640,600)


cumzval<-c(0.9029,
0.2495,-0.7888,
-2.0999,-1.9629,
-1.8674,-1.7743,
-1.2929,-1.0667,
-0.9152,-0.666,
-0.3349,0.1078,
1.1894,2.2064,
3.2112,4.2022,
5.5064,6.8475,
8.3989,9.6806,
11.0578,12.5002,
14.0373,15.3932,
16.9835,18.7814)

cum_sample<-c(136,              186,
              190,              238,
              363,              419,
              455,              516,
              577,              647,
              660,              720,
              780,              878,
              894,              898,
              922,              930,
              1103,              1113,
              1172,              1633,
              1666,              1710,
              1752,              1784,
              1814)

Year=c(2000,2002,2002,2002,2004,2009,2009,2009,2012,2012,2012,2012,2012,
2014,2015,2015,2015,2015,2015,2016,2016,2016,2016,2017,2017,2017,2018)

cum_df<-data.frame("z-score"=cumzval, "Cumulative n"<-cum_sample, "Year"=Year)

#png("TSA.png", width=850, height =400)
cum_df %>% 
  ggplot(aes(cum_sample,z.score))+
  labs(y="Cumulative Z Score", x="Cumulative sample size")+
  geom_point()+
  geom_line(colour="blue", linetype="dashed")+
  ylim(c(-15,15))+
  xlim(c(0,5000))+
  annotate("text", x = 1, y = 10, label = sprintf('\u2b61'),size=30) +
  annotate("text", x = 3000, y = 10, label ="Favours automatic recorder",size=4) +
  annotate("text", x = 1, y = -10, label = sprintf('\u2b63'),size=30) +
  annotate("text", x = 3000, y = -10, label ="Favours human recorder",size=4) +
  geom_hline(yintercept = 2, colour="red",linetype="dotted")+
  geom_hline(yintercept = -2, colour="red",linetype="dotted")+
  geom_text_repel(aes(label=Year),hjust=0.5, vjust=0)+
  theme_cowplot()


```


