---
title: "Evidence accumulation for tackling research waste"
csl: nature.csl
output:
  pdf_document:
    fig_caption: yes
  word_document: 
    fig_caption: yes
  html_document: 
    fig_caption: yes
bibliography: bibliography.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```



Matthew J. Grainger^1^*, Friederike C. Bolam^2^, Gavin B. Stewart^2^, Erlend B. Nilsen^1^

^1^Norwegian Institute for Nature Research, P.O. Box 5685 Torgarden, 7485, Trondheim, Norway

^2^Modelling Evidence and Policy Research Group, School of Natural and Environmental Sciences, Ridley Building 2, Claremont Road, Newcastle upon Tyne NE1 7RU, UK  


*corresponding author: matthew.grainger\@nina.no

*There is an immediate need for a change in research workflows so that pre-existing knowledge is better utilised in designing new research. A formal assessment of the accumulated knowledge prior to research approval would reduce the waste of already limited resources caused by asking low priority questions.*

“Research waste” is defined as research outcomes with no societal benefits [@glasziou2018research]. This occurs when the knowledge generated is either not innovative and novel, when it is not applicable to real-world situations, or when the research effort itself does not have societal impact (e.g. training students or engaging stakeholders). Waste can occur at any stage of the research process [@chalmers2009avoidable]; question setting; methods; accessibility; and reporting (Table 1). In medicine, research waste is a well-established concept, and in 2009 research waste was estimated to cost US$85bn [@chalmers2009avoidable], with few signs of improvement in the last decade [@glasziou2018research]. There is little reason to believe that the situation is substantially different in ecology and conservation, although there are no field-wide formal assessments of research waste.

Emerging topics are beginning to address some of the factors that result in wasted research efforts (Table 1). In particular, there is increased focus on methodological improvements in individual studies (e.g. [@fraser2018questionable], [@nilsen_bowler_linnell_2019]),  and on open science leading to improved accessibility and reporting [@gurevitch2018meta]. Less formal effort is devoted to the question setting stage. Here we suggest that “Evidence Synthesis” should be considered an additional stage of research (Table1, Supplementary Figure 1)  which closes the  research process into a loop,  leading to additional benefits in terms of reducing research waste at the question setting stage.  

# Reducing waste in question setting
There are two related areas where research waste can be reduced by taking into account the existing body of evidence through evidence synthesis methods.

## Low priority questions

New studies may ask low priority questions - those that are irrelevant to stakeholders. The remedy to this is to include stakeholders in the research commissioning process [@chalmers2009avoidable]. Evidence synthesis, or horizon scanning for novel problems, should be used to provide evidence to practitioners, researchers and other stakeholders so that they can identify research gaps that are important to them and to develop future questions [@gold2013prioritizing]. 

## The answer is already known with certainty

If a topic has been sufficiently addressed in the existing literature we might already know the outcome with high certainty. Further studies that fail to leverage this existing knowledge are at risk of wasting research resources. There are a variety of tools available for research-funders and researchers to assess the state of knowledge on the topic of interest. For example, systematic maps (also known as Evidence gap maps or Evidence maps), were designed to give an overview of the available evidence on a broad topic [@saran2018evidence]. They can highlight where there is enough available evidence for a systematic review or where primary research is required due to a lack of evidence. However, users of systematic maps should be aware that the number of papers available on a topic does not equate to the strength of evidence which should be formally examined before making conclusions about the adequacy of evidence [@stewart2015use]. Systematic reviews can be used to synthesise knowledge about a narrow topic such as the evidence for the effectiveness of an intervention and can provide a statistical summary of the pooled effect size. The statistical combination of numerical data extracted from the evidence base during the process of a systematic review is known as meta-analysis. Meta-analysis is increasingly used in conservation and ecology [@gurevitch2018meta] providing an understanding of the magnitude of the known effect of an intervention across individual studies. These results can be used to identify what new research can add to the current evidence base. Although evidence synthesis can be time consuming (opensource tools for predicting the time investment e.g. https://github.com/mjwestgate/PredicTER are available) the investment in time will facilitate less wasteful research.

## Identifying research waste with cumulative meta-analysis

In medicine, one additional tool used to quantify research waste is cumulative meta-analysis. A cumulative meta-analysis typically describes the accumulation of evidence (e.g., about the effectiveness of an intervention) across time, and available estimates are added to the analysis in chronological order [@lau1992cumulative]. Using cumulative meta-analysis, one can identify if there is sufficient evidence to be confident that a reported effect is true. Cumulative meta-analyses demonstrate how new research is frequently undertaken generating research waste, even when effect sizes are temporally stable and precise [@lau1992cumulative]. Researchers in domains relying on heterogeneous observational studies (such as ecologists) should beware of temporal instability of effects [@koricheva2019temporal] which should be considered as part of the strength of the existing evidence-base. We demonstrate how the approach can be integrated into conservation and applied ecology workflows,  see Box 1. Cumulative meta-analysis has already been used in our field to assess time-lag bias [@leimu2004cumulative] but is not commonly used in the way we show here. 

## Caveats

There are several important caveats that need to be addressed. The heterogeneity in reporting and the drive for novelty in publications means that meta-analysis is currently challenging in applied ecology. There might not be sufficient good quality research to quantify the cumulative effect of even some apparently well studied phenomena. Power analysis can be used to determine if there is enough primary literature to determine stability of a cumulative effect. Researchers are best placed to add to the evidence base by ensuring that they use comparable measures of outcomes rather than novel ones.  
In addition, publication bias, where the direction of statistical significance of the outcome influences the decision to publish the result, might bias the evidence base available. This is a major caveat for all evidence synthesis approaches, but one which can be identified. Funnel plots can be used to identify the potential for non-publication of results (i.e. those of small effect size). With cumulative meta-analysis one can explore publication bias [@leimu2004cumulative] by accumulating the effect sizes in order of journal impact factor for example. Although this method makes it possible to detect publication bias it will not solve the underlying problem, and researchers should endeavour to reduce publication bias by following open science principles (Table 1). 
Without deliberate research programs of sequential research focused on specific questions in ecology, as proposed in [@nichols2019accumulating], we need to find ways of  synthesising diverse information sources. Methodologists propose use of systems models to combine empirical evidence from systematic reviews and meta-analysis with expert opinion which allows key areas of uncertainty in a topic to be identified and prioritised for research focus (e.g. [@carrick2018planting]).  Formal value of information analysis can then be undertaken if a decision-theoretic framework exists.

## Outlook

Research waste can be reduced and it is the responsibility of research funders, research institutions as well as individual researchers to do so. Researchers and funders could search for existing research syntheses in the literature and on synthesis platforms (e.g. https://www.conservationevidence.com/). We agree with the statement targeted at medicine 25 years ago that “We need...better research, and research done for the right reasons” [@altman1994scandal]. Without a change in focus ecology and conservation funding will continue to be wasted which will be detrimental to our efforts to provide solutions to global societal challenges.   

### Box 1 Using cumulative meta-analysis to make research decisions

=======

Research waste can be reduced and it is the responsibility of research funders, research institutions as well as individual researchers to do so. Researchers and funders could search for existing research syntheses in the literature and on synthesis platforms (e.g. https://www.conservationevidence.com/). We agree with the statement targeted at medicine 25 years ago that “We need...better research, and research done for the right reasons” [@altman1994scandal]. Without a change in focus ecology and conservation funding will continue to be wasted which will be detrimental to our efforts to provide solutions to global societal challenges.   

### Box 1 Using cumulative meta-analysis to make research decisions

Imagine you, as a researcher or research funder, want to assess the potential for acoustic recorders to replace human observers for estimating bird abundance. Do we need another research study to determine this? Here we outline an example decision process which would serve to reduce research waste.

* **Is there previous knowledge available on this topic?** Technological advances over the last two decades have allowed this potential to be explored fully, and well over 150 field studies have sought to answer this question. A meta-analysis in 201815 explored the pooled effect of these studies using a meta-analytic approach to estimate species richness of birds. Twenty-eight primary studies published between 2000 and 2017 were included in the meta-analysis. Based on the combined evidence from the included studies, they concluded that when human observers (using point counts) and sound recorders sample areas of equal size then there is no difference between estimates of bird species richness. When properly conducted (see specific advice in [@darras2018comparing]), it can be inferred that sound recorders can be used to monitor aspects of biodiversity as efficiently as human observers. 
*	**Do we need another study to quantify the effect?** We adapted the analysis of [@darras2018comparing] to demonstrate the use of cumulative meta-analysis (see Supplementary Methods). For the 14 studies conducted since 2014, the effect size (i.e. the magnitude of the difference between intervention and control) of studies was consistently close to 0.07  (a difference of around 1 species; Figure 1). This means that there was no clear difference between acoustic recorders and human observers on bird point counts. It would be wasteful to fund yet another study that addressed this specific question.
*	**What next?** If you were interested in acoustic sampling as a means to sample bird species richness you could proceed with confidence that using acoustic sampling is as effective as human observers in the field. If you are interested in acoustic sampling specifically you could look for substantial anomalies or heterogeneity between studies in the meta-analysis and design a study trying to understand these differences. 

# References {-}

<div id="refs"></div>

\newpage 


```{r Make use of the code from Darras et al, message=FALSE, warning=FALSE, include=FALSE}
#Load libraries
library(readr)
library(data.table)
library(ggplot2)
library(scales)
library(cowplot)
library(metafor)
library(nlme)
library(MuMIn)
library(effects)
library(tidyverse)
library(ggsci)
library(gganimate)
library(ggthemes)
library(bookdown)

#Code from the original paper (Darras et al. 2018)
#Prepare data and Run metaanalysis
#standard error function
se <- function(x) sqrt(var(x,na.rm=TRUE)/length(na.omit(x)))

meta0=fread("meta-analysis - data.csv")
#give ID to all studies
meta0[,study_ID:=1:nrow(meta0)]
#remove Acevedo due to unequal sampling
meta0=meta0[first_author!="Acevedo"]
#convert to numeric
meta0=meta0[,total_time_min:=as.numeric(total_time_min)]

# Table 1 -----------------------------------------------------------------

#format column headers
meta.studies=meta0[,.(Publication=paste(first_author,year),`Sampling time (min)`=total_time_min,Microphone=microphone,`Signal to noise ratio (minimum, dB)`=signal_to_noise,`Height (cm)`=height_cm,`Number of Microphones`=number_microphones)]

# community differences ---------------------------------------------------

#compute total richness with both methods combined
meta0[,c("gamma_total_unlimited","gamma_total_identical")
      :=.(gamma_point_unlimited+unique_sound_unlimited,gamma_point_identical+unique_sound_identical)]

meta0[simultaneous_methods==1,.(common_species_unlimited=mean((gamma_point_unlimited-unique_point_unlimited)/gamma_total_unlimited,na.rm=T)
                                ,unique_point_unlimited=mean(unique_point_unlimited/gamma_total_unlimited,na.rm=T)
                                ,unique_sound_unlimited=mean(unique_sound_unlimited/gamma_total_unlimited,na.rm=T)
                                ,common_species_identical=mean((gamma_point_identical-unique_point_identical)/gamma_total_identical,na.rm=T)
                                ,unique_point_identical=mean(unique_point_identical/gamma_total_identical,na.rm=T)
                                ,unique_sound_identical=mean(unique_sound_identical/gamma_total_identical,na.rm=T))]

# calculate ROM ----------------------------------------------------------

#calculate log transformed ratio of means for alpha and gamma richness
#alpha richness identical
alpha.identical=data.table(summary(escalc(measure="ROM"
                                          ,m1i=alpha_sound_identical,m2i=alpha_point_identical
                                          ,sd1i=alpha_sound_sd_identical,sd2i=alpha_point_sd_identical
                                          ,n1i=alpha_sound_n_identical,n2i=alpha_point_n_identical
                                          ,data=meta0[!is.na(alpha_point_n_identical)])))

#alpha richness unlimited
alpha.unlimited=data.table(summary(escalc(measure="ROM"
                                          ,m1i=alpha_sound_unlimited,m2i=alpha_point_unlimited
                                          ,sd1i=alpha_sound_sd_unlimited,sd2i=alpha_point_sd_unlimited
                                          ,n1i=alpha_sound_n_unlimited,n2i=alpha_point_n_unlimited
                                          ,data=meta0[!is.na(alpha_point_n_unlimited)])))
#gamma richness identical
gamma.identical=data.table(summary(escalc(measure="ROM"
                                          ,m1i=gamma_sound_identical,m2i=gamma_point_identical
                                          ,sd1i=rep(0,nrow(meta0[!is.na(gamma_total_identical)])),sd2i=rep(0,nrow(meta0[!is.na(gamma_total_identical)]))
                                          ,n1i=total_time_min,n2i=total_time_min
                                          ,data=meta0[!is.na(gamma_total_identical)])))

#gamma richness unlimited
gamma.unlimited=data.table(summary(escalc(measure="ROM"
                                          ,m1i=gamma_sound_unlimited,m2i=gamma_point_unlimited
                                          ,sd1i=rep(0,nrow(meta0[!is.na(gamma_total_unlimited)])),sd2i=rep(0,nrow(meta0[!is.na(gamma_total_unlimited)]))
                                          ,n1i=total_time_min,n2i=total_time_min
                                          ,data=meta0[!is.na(gamma_total_unlimited)])))

#merge all ROM data together
meta1=merge(meta0,merge(alpha.identical[,.(study_ID,alpha_ROM_identical=yi,alpha_variance_ROM_identical=vi,alpha_ci.lb_identical=ci.lb,alpha_ci.ub_identical=ci.ub)]
                        ,merge(alpha.unlimited[,.(study_ID,alpha_ROM_unlimited=yi,alpha_variance_ROM_unlimited=vi,alpha_ci.lb_unlimited=ci.lb,alpha_ci.ub_unlimited=ci.ub)]
                               ,merge(gamma.unlimited[,.(study_ID,gamma_ROM_unlimited=yi,gamma_variance_ROM_unlimited=vi)]
                                      ,gamma.identical[,.(study_ID,gamma_ROM_identical=yi,gamma_variance_ROM_identical=vi)]
                                      ,all=T,by="study_ID"),all=T,by="study_ID"),all=T,by="study_ID"),all=T,by="study_ID")


# identical range (alpha) --------------------------------------------------------------

#create publication=level column for random effect
meta1[,publication:=paste(first_author,year)]
meta1<-meta1 %>% 
  mutate("year"=gsub("a"," ", year)) %>% 
  mutate("year"=gsub("b"," ", year))


#models for identical ranges
RMA_alpha_identical=rma.mv(yi=alpha_ROM_identical,V=alpha_variance_ROM_identical
                           ,data=meta1,random=list(~1|publication))
forest(RMA_alpha_identical)

```


```{r Add Trial, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= "Cumulative forest plot of the meta-analysis of Darras et al. (2018) on the difference between human observers and acoustic recorders in terms of species richness. The green line indicates the line of zero effect, the blue dots indicate the cumulative effect size with 95% confidence intervals. Studies are ordered by publication year with the earliest studies at the top and the latest studies at the bottom.\\label{forest}"}
### Add cumulative meta-analysis
res <- rma(RMA_alpha_identical$yi, RMA_alpha_identical$vi, data=meta1, slab=paste(meta1$first_author, meta1$year, sep=", "))
cres<-cumul(res, order=order(meta1$year))
#forest(cres, col="blue")
df<-data.frame("cite"=cres$slab, "est"=cres$estimate, "se"=cres$se)

p<-df %>% 
  rowid_to_column() %>% 
  mutate("Up"=(1.96*se)+est) %>% 
  mutate("Low"=(-1.96*se)+est) %>% 
  ggplot(aes(y=reorder(cite,-rowid), x=est, xmin=Low, xmax=Up))+
  geom_point(color = 'blue', size=3)+
  labs(x="Log ratio of means", y="")+
  geom_vline(xintercept = 0, linetype = "dashed", colour="green", size=1)+
  geom_errorbarh(height=.1, colour="blue", size=1)+
  ggthemes::theme_base()+
  theme(axis.line = element_line(colour = 'black', size = 1), 
        axis.ticks = element_line(colour = "black", size = 1))
p

#ggsave("C:/Users/matthew.grainger/OneDrive - NINA/Papers_in_prep/Cumulative_meta_analysis/Research_waste/Figures/Fig1._Cumulative_Forest.png", p, device = "png")

```

Table 1 can be found at: https://github.com/DrMattG/Research_waste/blob/master/Manuscript/Table1.pdf

